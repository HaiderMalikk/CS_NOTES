{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaaa8b5",
   "metadata": {},
   "source": [
    "# Model Building (reuseable model class)\n",
    "\n",
    "**Goal: You want to build a reusable, modular Keras model for text classification. Key points:**\n",
    "- Inputs: Integer token IDs (produced by your pipeline). Shape (batch_size, max_len).\n",
    "- Embedding: Converts token IDs → dense vectors. Essential for NLP.\n",
    "- Sequence encoder: Can be a BiLSTM or a Transformer block — this encodes order and context.\n",
    "- Dense layers: Optional intermediate processing to extract features.\n",
    "- Output layer: Softmax (or sigmoid if binary) — produces predictions.\n",
    "- Independent of training: This file just builds the model; compiling, LR schedules, and loss go in the training script.\n",
    "- Config-driven: So you can swap hyperparameters easily.\n",
    "\n",
    "**Why modular?**\n",
    "- Experimentation: Swap LSTM → Transformer → CNN blocks without touching training code.\n",
    "- Clarity: Separation of concerns: pipeline → model → training loop.\n",
    "- Reproducibility: build_model(config) ensures everyone can rebuild the same model easily.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow keras numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb560d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "\"\"\"\n",
    "model_builder — modular Keras model for text classification\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(\n",
    "    # now we define all the parameters for our model\n",
    "    vocab_size: int, \n",
    "    max_len: int = 128,\n",
    "    embed_dim: int = 128,\n",
    "    num_classes: int = 2,\n",
    "    encoder_type: str = 'bilstm',  # options: 'bilstm', 'transformer'\n",
    "    lstm_units: int = 128,\n",
    "    transformer_heads: int = 4,\n",
    "    transformer_ff_dim: int = 128,\n",
    "    dense_units: int = 64,\n",
    ") -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build a text classification model with modular encoder options.\n",
    "    \n",
    "    Parameters:\n",
    "        vocab_size: Size of vocabulary\n",
    "        max_len: Max sequence length\n",
    "        embed_dim: Embedding dimension\n",
    "        num_classes: Number of output classes\n",
    "        encoder_type: 'bilstm' or 'transformer'\n",
    "        lstm_units: Units for BiLSTM layer\n",
    "        transformer_heads: Attention heads for transformer\n",
    "        transformer_ff_dim: Feed-forward dim for transformer\n",
    "        dense_units: Units for intermediate Dense layer\n",
    "    \n",
    "    Returns:\n",
    "        Keras Model (not compiled)\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(max_len,), dtype='int32', name='input_ids') # Input layer this is where we define the shape and type of our input data this layer takes in sequences of integers of length max_len (ie tokenized text data)\n",
    "\n",
    "    # 1️⃣ Embedding\n",
    "    x = layers.Embedding(vocab_size, embed_dim, mask_zero=True, name='embedding')(inputs) # we create an embedding layer that converts input tokens into dense vectors of fixed size (this takes our tokenized input and maps each token to a vector of size embed_dim)\n",
    "\n",
    "    # 2️⃣ Sequence encoder (help understand the context of the sequence)\n",
    "    # Choose between BiLSTM or Transformer for sequence encoding\n",
    "    # Use BiLSTM when you need to capture sequential dependencies in both directions\n",
    "    # and your dataset is relatively small or you want a simpler model.\n",
    "    # Use Transformer when you need to capture global context, work with longer sequences,\n",
    "    # or have a larger dataset that can benefit from its parallel processing capabilities.\n",
    "    if encoder_type.lower() == 'bilstm': # stands for bidirectional LSTM is a type of RNN \n",
    "        \n",
    "        # BiLSTM (Bidirectional LSTM) Layer:\n",
    "        # LSTM (Long Short-Term Memory) is a type of RNN (Recurrent Neural Network) that is capable of learning long-term dependencies in sequential data.\n",
    "        # Bidirectional LSTM processes the input sequence in both forward and backward directions, capturing context from both past and future tokens.\n",
    "        # This is particularly useful in NLP tasks where understanding the context of a word depends on both preceding and succeeding words.\n",
    "        x = layers.Bidirectional(\n",
    "            layers.LSTM(lstm_units),  # LSTM layer with `lstm_units` specifying the number of units in the LSTM cell\n",
    "            name='bilstm'             # Name of the layer for identification\n",
    "        )(x)\n",
    "    elif encoder_type.lower() == 'transformer':\n",
    "        # Simple transformer block\n",
    "        # Multi-Head Attention: This layer allows the model to focus on different parts of the input sequence\n",
    "        # simultaneously. It computes attention scores for each token in the sequence relative to all other tokens.\n",
    "        # `num_heads` specifies the number of attention heads, and `key_dim` is the dimensionality of the query/key vectors.\n",
    "        attn_output = layers.MultiHeadAttention(\n",
    "            num_heads=transformer_heads,  # Number of attention heads\n",
    "            key_dim=embed_dim,           # Dimensionality of the query/key vectors\n",
    "            name='transformer_attn'      # Name of the attention layer\n",
    "        )(x, x)  # The input `x` is used as both the query and the key/value (self-attention).\n",
    "\n",
    "        # Residual Connection: Adds the original input `x` back to the attention output.\n",
    "        # This helps preserve the original information and improves gradient flow during training.\n",
    "        x = layers.Add(name='residual_add')([x, attn_output])\n",
    "\n",
    "        # Layer Normalization: Normalizes the output of the residual connection.\n",
    "        # This stabilizes training and ensures that the values are on a similar scale.\n",
    "        x = layers.LayerNormalization(name='layer_norm')(x)\n",
    "\n",
    "        # Feed-Forward Network (FFN): A dense layer with a ReLU activation function.\n",
    "        # This introduces non-linearity and allows the model to learn more complex representations.\n",
    "        ff_output = layers.Dense(\n",
    "            transformer_ff_dim,  # Dimensionality of the feed-forward layer\n",
    "            activation='relu',   # Activation function\n",
    "            name='ff_dense'      # Name of the dense layer\n",
    "        )(x)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoder_type={encoder_type}\")\n",
    "\n",
    "    # 3️⃣ Dense intermediate layer (helps the model learn more complex features by adding an additional layer before the output layer and using relu activation to introduce non-linearity)\n",
    "    x = layers.Dense(dense_units, activation='relu', name='dense')(x)\n",
    "\n",
    "    # 4️⃣ Output layer (classification layer)\n",
    "    if num_classes == 1: \n",
    "        # Binary classification\n",
    "        outputs = layers.Dense(1, activation='sigmoid', name='output')(x) # for binary classification we use a single neuron with sigmoid activation which outputs a probability between 0 and 1 (probability of the positive class i.e if the input text belongs to the positive class then the output will be close to 1 otherwise close to 0)\n",
    "    else:\n",
    "        # Multi-class classification\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', name='output')(x) # since there can be many output classes we use softmax activation which outputs a probability distribution over all classes (the sum of all output probabilities will be 1 and the class with the highest probability is chosen as the predicted class)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='text_classifier') # create a Keras model with the specified inputs and outputs ( we do this after we have trained our model on our processed text data so we have a ready to use model for making predictions on new text data)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89883a68",
   "metadata": {},
   "source": [
    "### Key Notes\n",
    "- Encoders modular: Swap encoder_type without changing downstream code.\n",
    "- Dense units independent: You can tune intermediate features easily.\n",
    "- Output flexible: Automatically chooses sigmoid (binary) or softmax (multi-class).\n",
    "- No compile: Leave optimizer, loss, LR schedules, metrics in train_fit.py.\n",
    "- Embedding uses mask_zero=True: Ensures LSTM ignores padded positions.\n",
    "- Transformer block: Minimal example to understand mechanics; can expand to full stacked blocks later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe698e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 19:22:51.911266: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2025-11-12 19:22:51.911315: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-12 19:22:51.911321: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762993371.912032 2044201 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1762993371.912149 2044201 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"text_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"text_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,280,000\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m263,168\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m130\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,559,746</span> (5.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,559,746\u001b[0m (5.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,559,746</span> (5.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,559,746\u001b[0m (5.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example usage \n",
    "config = {\n",
    "    \"vocab_size\": 10000,\n",
    "    \"max_len\": 128,\n",
    "    \"embed_dim\": 128,\n",
    "    \"num_classes\": 2,\n",
    "    \"encoder_type\": \"bilstm\",\n",
    "    \"lstm_units\": 128,\n",
    "    \"dense_units\": 64,\n",
    "}\n",
    "\n",
    "model = build_model(**config)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75ef4f",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "\n",
    "- What it is (is short): the NotEqual entry in your model is just a check that creates a True/False mask saying “is this token not padding (0)?”\n",
    "- Why we need it: when sentences are different lengths we pad short ones with 0 so all rows have the same length. The mask tells the model which positions are real words and which are just padding, so the model can ignore padding.\n",
    "- Tiny concrete example:\n",
    "    - Input token ids (two examples, padded to length 4): \n",
    "     [[5, 3, 0, 0],\n",
    "     [2, 7, 9, 0]]\n",
    "    - Mask computed by input_ids != 0:\n",
    "    [[True, True, False, False],\n",
    "    [True, True, True, False]]\n",
    "- Meaning: False positions are padding and should be ignored.\n",
    "\n",
    "- How it appears in your model: Embedding(..., mask_zero=True) tells Keras to treat 0 as padding; Keras creates the not_equal op (no trainable params) and passes that mask to layers like LSTM so they skip padded timesteps.\n",
    "- Simple takeaway: masking prevents padding from changing model outputs. If you don’t want it, set mask_zero=False on the Embedding (but then padding will be treated like a real token).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dbbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 19:26:13.301249: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"text_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"text_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │        \u001b[38;5;34m800\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m1,600\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m68\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m5\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,473</span> (9.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,473\u001b[0m (9.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,473</span> (9.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,473\u001b[0m (9.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 19:26:13.857207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6935\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6935\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6930\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6930\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 0.6925\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 0.6925\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5833 - loss: 0.6921\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5833 - loss: 0.6921\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7292 - loss: 0.6917\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7292 - loss: 0.6917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853ms/step\n",
      "Prediction (probability of positive): 0.4986373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853ms/step\n",
      "Prediction (probability of positive): 0.4986373\n"
     ]
    }
   ],
   "source": [
    "# using model \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ----------------------------\n",
    "# 1️⃣ Tiny example dataset\n",
    "# ----------------------------\n",
    "texts = [\n",
    "    \"I love this movie\",\n",
    "    \"This film was terrible\",\n",
    "    \"Amazing plot and acting\",\n",
    "    \"Horrible movie experience\",\n",
    "    \"Loved it, would watch again\",\n",
    "    \"Worst movie ever\"\n",
    "]\n",
    "labels = [1, 0, 1, 0, 1, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "# Convert to tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((texts, labels))\n",
    "\n",
    "# ----------------------------\n",
    "# 2️⃣ Text preprocessing (tokenization)\n",
    "# ----------------------------\n",
    "vocab_size = 50\n",
    "max_len = 10\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_len\n",
    ")\n",
    "vectorize_layer.adapt(dataset.map(lambda x, y: x))\n",
    "\n",
    "def preprocess(text, label):\n",
    "    # `text` here is a scalar string tensor (e.g. b\"I love this movie\").\n",
    "    # TextVectorization accepts scalar strings when mapping over a\n",
    "    # dataset and will produce integer sequences after the dataset is\n",
    "    # batched. Do NOT expand dimensions here — returning\n",
    "    # `vectorize_layer(text)` keeps shapes compatible with the model.\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "dataset = dataset.map(preprocess).batch(2).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ----------------------------\n",
    "# 3️⃣ Build model\n",
    "# ----------------------------\n",
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    max_len=max_len,\n",
    "    embed_dim=16,\n",
    "    num_classes=1,\n",
    "    encoder_type='bilstm',\n",
    "    lstm_units=8,\n",
    "    dense_units=4\n",
    ")\n",
    "\n",
    "# Compile model (optimizer, loss, metrics)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----------------------------\n",
    "# 4️⃣ Train model on tiny dataset\n",
    "# ----------------------------\n",
    "model.fit(dataset, epochs=5)\n",
    "\n",
    "# ----------------------------\n",
    "# 5️⃣ Test with a new example\n",
    "# ----------------------------\n",
    "test_text = tf.constant([\"I hated this movie\"])  # shape (1,)\n",
    "# vectorize_layer expects a 1-D batch of strings; pass test_text directly\n",
    "test_input = vectorize_layer(test_text)\n",
    "pred = model.predict(test_input)\n",
    "print(\"Prediction (probability of positive):\", pred[0][0]) # outputs a probability between 0 and 1 0= negative, 1= positive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d905464",
   "metadata": {},
   "source": [
    "### What’s happening here\n",
    "- Dataset: Tiny list of movie reviews + labels → converted to tf.data.Dataset.\n",
    "- TextVectorization: Tokenizes words → integers, pads/truncates to max_len=10.\n",
    "- Pipeline: .map(preprocess), .batch(2), .prefetch() ensures efficient feeding.\n",
    "- Model: Uses the build_model() you created — embedding → BiLSTM → dense → sigmoid.\n",
    "- Training: We train for a few epochs on the tiny dataset.\n",
    "- Prediction: Shows how to pass a new raw text through the same preprocessing pipeline → model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
