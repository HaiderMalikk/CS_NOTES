{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca7f4c6",
   "metadata": {},
   "source": [
    "Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1662ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ðŸ“š Full Scikit-Learn (sklearn) Interview Guide\n",
    "---\n",
    "\n",
    "1. What is Scikit-Learn?\n",
    "\n",
    "- Scikit-Learn (sklearn) is Pythonâ€™s most popular library for:\n",
    "  - Machine Learning (ML) algorithms\n",
    "  - Data preprocessing\n",
    "  - Model selection and evaluation\n",
    "  - Pipelines (end-to-end workflows)\n",
    "\n",
    "- Key features:\n",
    "  - Easy-to-use API\n",
    "  - Lots of models (classification, regression, clustering, etc.)\n",
    "  - Integrates well with NumPy, Pandas, and Matplotlib\n",
    "\n",
    "---\n",
    "\n",
    "2. Installation\n",
    "\n",
    "Use pip:\n",
    "    pip install scikit-learn\n",
    "\n",
    "---\n",
    "\n",
    "3. Basic Workflow (VERY IMPORTANT)\n",
    "\n",
    "Every project with Scikit-Learn typically follows this pattern:\n",
    "\n",
    "    1. Load Data\n",
    "    2. Preprocess Data\n",
    "    3. Split Data (train/test)\n",
    "    4. Choose a Model\n",
    "    5. Train the Model\n",
    "    6. Predict on new data\n",
    "    7. Evaluate Performance\n",
    "    8. Tune Hyperparameters (optional)\n",
    "    9. (Optional) Save the Model\n",
    "\n",
    "---\n",
    "\n",
    "4. Practical Hands-On Example\n",
    "\n",
    "Dataset: Iris Dataset (small, famous ML dataset)\n",
    "\"\"\"\n",
    "\n",
    "# 1. Import libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "\"\"\"\n",
    "Explanation:\n",
    "- `load_iris` loads a built-in dataset (flowers, 3 classes).\n",
    "- `train_test_split` splits data into training and testing parts.\n",
    "- `StandardScaler` standardizes features by removing mean and scaling to unit variance.\n",
    "- `LogisticRegression` is a classification model.\n",
    "- `accuracy_score` and `classification_report` are used to evaluate how good the model is.\n",
    "- `GridSearchCV` is used for hyperparameter tuning.\n",
    "- `joblib` is used to save the trained model to disk.\n",
    "\"\"\"\n",
    "\n",
    "# 2. Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\"\"\"\n",
    "X = features (petal length, width, etc.)\n",
    "y = labels (flower types)\n",
    "\"\"\"\n",
    "\n",
    "# 3. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "- 70% training data\n",
    "- 30% testing data\n",
    "- random_state ensures reproducibility\n",
    "\"\"\"\n",
    "\n",
    "# 4. Preprocessing (feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\"\"\"\n",
    "- Fit on training data only (important to avoid data leakage)\n",
    "- Then transform both training and testing sets\n",
    "\"\"\"\n",
    "\n",
    "# 5. Choose and Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\"\"\"\n",
    "- `fit` method trains the model using training data\n",
    "\"\"\"\n",
    "\n",
    "# 6. Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\"\"\"\n",
    "- `predict` method predicts labels for the testing set\n",
    "\"\"\"\n",
    "\n",
    "# 7. Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\"\"\"\n",
    "- Accuracy: proportion of correctly predicted labels\n",
    "- Classification report: precision, recall, f1-score, support\n",
    "\"\"\"\n",
    "\n",
    "# 8. Tune Hyperparameters (Optional)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "\n",
    "\"\"\"\n",
    "- GridSearchCV searches over combinations of hyperparameters\n",
    "- Cross-validation (cv=5) is used to avoid overfitting\n",
    "\"\"\"\n",
    "\n",
    "# 9. Save the Model (Optional)\n",
    "joblib.dump(grid_search.best_estimator_, \"best_logistic_model.pkl\")\n",
    "\n",
    "\"\"\"\n",
    "- Saves the best trained model to disk using joblib\n",
    "- Can later load it with `model = joblib.load(\"best_logistic_model.pkl\")`\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
